{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sarsa:\n",
    "    \n",
    "    def __init__(self, action, gamma=0.642, alpha=0.124):\n",
    "        \n",
    "        self.action = action\n",
    "        self.alpha  = alpha\n",
    "        self.gamma  = gamma\n",
    "        self.terminal_state = s_term\n",
    "        \n",
    "    def Calculate_Q_values(self, state, action):\n",
    "        \"\"\"\n",
    "        This function estimates the value for the action value function\n",
    "        \"\"\"\n",
    "        self.Qvalue = Q(state, action)\n",
    "        \n",
    "        #condition for terminal state Q(s,a) = 0.0\n",
    "        \n",
    "        if (state==s_term):\n",
    "            \n",
    "            return 0.0\n",
    "        else:\n",
    "            return Q_value\n",
    "        \n",
    "    def action_selection(self, epsilon=0.9):\n",
    "        \n",
    "        \"\"\"\n",
    "        this function select action for a particular state\n",
    "        \"\"\"\n",
    "        #the probability condition \n",
    "        if random.random() < 0.9:\n",
    "            \n",
    "            action = random.choice(self.action)\n",
    "        else:\n",
    "        #selecting the action that maximizes the Q_value\n",
    "        \n",
    "            Q_values = [self.Calculate_Q_values(state, action) for action in self.action]\n",
    "            \n",
    "            #find the max Q value\n",
    "            Q_max = max(Q_values)\n",
    "            \n",
    "            #estimate the count of Q values where it is max\n",
    "            count_Q_max = Q_values.count(Q_max)\n",
    "            \n",
    "            #condition for identical Q_max values for many actions\n",
    "            if (count_Q_max > 1):\n",
    "                \n",
    "                for i in range(len(self.action)):\n",
    "                    #track the indices of the \n",
    "                    if Q_values[i] == Q_max:\n",
    "                        \n",
    "                        best_action_idxs = i\n",
    "                        \n",
    "                        action_idx = random.choice(best_action_idxs)\n",
    "                    else:\n",
    "                        \n",
    "                        action_idx = Q_values.index(Q_max)\n",
    "                \n",
    "                        return self.action[best_action_idx], self.action[action_idx]\n",
    "                \n",
    "                \n",
    "    def update(self, state, action, reward, s_next):\n",
    "        \"\"\"\n",
    "        this function updates the Qvalue\n",
    "        \"\"\"\n",
    "        Q_prime = self.Calculate_Q_values(state=s_next\n",
    "                , action=self.select_greedy_action(s_next))\n",
    "        \n",
    "        \n",
    "        Q_current = self.Q_value((state, action), None)\n",
    "        \n",
    "        if Q_current:\n",
    "            self.Q_value[(state, action)] = self.reward\n",
    "        else:\n",
    "            self.Q_value[(state, action)] = Q_current + (self.alpha*(self.reward + self.gamma*Q_prime-Q_current))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
